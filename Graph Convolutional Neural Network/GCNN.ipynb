{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer():\n",
    "    def __init__(self, nInputs, nOutputs, activation=None, name=''):\n",
    "        self.nInputs = nInputs\n",
    "        self.nOutputs = nOutputs\n",
    "        self.W = glorot_uniform(self.nOutputs, self.nInputs)\n",
    "        self.activation = activation\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, A, X, W=None):\n",
    "        self._X = (A @ X).T # message passing\n",
    "\n",
    "        if W is None:\n",
    "            W = self.W\n",
    "        \n",
    "        H = W @ self._X # net input\n",
    "        if self.activation != None:\n",
    "            H = self.activation(H) \n",
    "        self._H = H\n",
    "        return self._H.T\n",
    "\n",
    "    def backward(self, optim, update=True):\n",
    "        dtanh = 1 - np.asarray(self._H.T)**2\n",
    "        d2 = np.multiply(optim.out, dtanh)\n",
    "\n",
    "        optim.out = d2 @ self.W\n",
    "\n",
    "        dW = np.asanyarray(d2.T @ self._X.T) / optim.bs\n",
    "        dwDecay = self.W * optim.wd / optim.bs\n",
    "\n",
    "        if update:\n",
    "            self.W -= optim.lr * (dW + dwDecay)\n",
    "            return dW + dwDecay\n",
    "\n",
    "class GradientDescentOptim():\n",
    "    def __init__(self, lr, wDecay):\n",
    "        self.lr = lr\n",
    "        self.wDecay = wDecay\n",
    "        self._yHat = None\n",
    "        self._y = None\n",
    "        self._out = None\n",
    "        self.bs = None\n",
    "        self.trainNodes = None\n",
    "\n",
    "    def __call__(self, yHat, y, trainNodes=None):\n",
    "        self.y = y\n",
    "        self.yHat = yHat\n",
    "\n",
    "        if trainNodes != None:\n",
    "            self.trainNodes = trainNodes\n",
    "        else:\n",
    "            self.trainNodes = np.arange(yHat.shape[0])\n",
    "\n",
    "        self.bs = self.trainNodes.shape[0]\n",
    "\n",
    "    @property\n",
    "    def out(self):\n",
    "        return self._out\n",
    "    \n",
    "    @out.setter\n",
    "    def out(self, y):\n",
    "        self._out = y\n",
    "\n",
    "class SoftmaxLayer():\n",
    "    def __init__(self, nInputs, nOutputs, name=''):\n",
    "        self.nInputs = nInputs\n",
    "        self.nOutputs = nOutputs\n",
    "        self.W = glorot_uniform(self.nOutputs, self.nInputs)\n",
    "        self.b = np.zeros((self.nOutputs, 1))\n",
    "        self.name = name\n",
    "        self._X = None\n",
    "\n",
    "    def shift(self, proj):\n",
    "        shiftX = proj - np.max(proj, axis=0, keepdims=True)\n",
    "        exps = np.exp(shiftX)\n",
    "        return exps / np.sum(exps, axis=0, keepdims=True)\n",
    "\n",
    "    def forward(self, X, W=None, b=None):\n",
    "        self._X = X.T\n",
    "        if W is None:\n",
    "            W = self.W\n",
    "        if b is None:\n",
    "            b = self.b\n",
    "        \n",
    "        proj = np.asarray(W @ self._X) + b\n",
    "        return self.shift(proj).T\n",
    "\n",
    "    def backward(self, optim, update=True):\n",
    "        trainMask = np.zeros(optim.yHat.shape[0])\n",
    "        trainMask[optim.trainNodes] = 1\n",
    "        trainMask = trainMask.reshape((-1, 1))\n",
    "\n",
    "        d1 = np.asarray((optim.yHat - optim.y))\n",
    "        d1 = np.multiply(d1, trainMask)\n",
    "\n",
    "        optim.out = d1 @ self.W\n",
    "        dW = (d1.T @ self._X.T) / optim.bs\n",
    "        db = d1.T.sum(axis=1, keepdims=True) / optim.bs\n",
    "\n",
    "        dWDecay = self.W * optim.wDecay / optim.bs\n",
    "\n",
    "        if update:\n",
    "            self.W -= optim.lr * (dW + dWDecay)\n",
    "            self.b -= optim.lr * db.reshape(self.b.shape)\n",
    "\n",
    "        return dW + dWDecay, db.reshape(self.b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNN():\n",
    "    def __init__(self, nInputs, noutputs, nLayers, hiddenSizes, activation, seed=0):\n",
    "        self.nInputs = nInputs\n",
    "        self.nOutputs = noutputs\n",
    "        self.nLayers = nLayers\n",
    "        self.hiddenSizes = hiddenSizes\n",
    "\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        # Add input layer\n",
    "        self.layers.append(GCNLayer(nInputs, hiddenSizes[0], activation, name='in'))\n",
    "\n",
    "        # Add hidden layer\n",
    "        for layer in range(nLayers):\n",
    "            self.layers.append(GCNLayer(self.layers[-1].W.shape[0], hiddenSizes[layer], activation, name=\"hidden layer{}\".format(layer+1)))\n",
    "\n",
    "        # Output layer\n",
    "        self.layers.append(SoftmaxLayer(hiddenSizes[-1], noutputs, activation, name='out'))\n",
    "\n",
    "    def embedding(self, A, X):\n",
    "        H = X\n",
    "        for layer in self.layers[:-1]:\n",
    "            H = layer.forward(A, H)\n",
    "        return np.asarray(H)\n",
    "\n",
    "    def forward(self, A, X):\n",
    "        H = self.embedding(A, X)\n",
    "\n",
    "        p = self.layers[-1].forward(H)\n",
    "\n",
    "        return np.asarray(p)  \n",
    "\n",
    "\n",
    "    def backward(self, optim, update=True):\n",
    "        self.layers[-1].backward(optim)\n",
    "        for layer in reversed(self.layers):\n",
    "            H = layer.backward(optim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b0d3a5c74b875f8b1b4c8520dff914ee143b37c3d87e9c8a9097d445bc2d841"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
